Big O Rule Asymptotic Analysis
1. Worse case
2. Remove constants
3. Diff terms for Input
4. drop non dominant


-= How to solve a problem =-
1. When the interviewer says the question, write down the key points at the top (i.e. sorted array). Make sure you have all the details. Show how organized you are.
2. Make sure you double check: What are the inputs? What are the outputs?
3. What is the most important value of the problem? Do you have time, and space and memory,
etc.. What is the main goal?
4. Don't be annoying and ask too many questions.
5. Start with the naive/brute force approach. First thing that comes into mind. It shows that you’re able to think well and critically (you don't need to write this code, just speak about it).
6. Tell them why this approach is not the best (i.e. O(n^2) or higher, not readable, etc...)
7. Walk through your approach, comment things and see where you may be able to break things. Any repetition, bottlenecks like O(N^2), or unnecessary work? Did you use all the information the interviewer gave you? Bottleneck is the part of the code with the biggest Big O. Focus on that. Sometimes this occurs with repeated work as well.
8. Before you start coding, walk through your code and write down the steps you are going to follow.
9. Modularize your code from the very beginning. Break up your code into beautiful small pieces and add just comments if you need to.
10. Start actually writing your code now. Keep in mind that the more you prepare and understand what you need to code, the better the whiteboard will go. So never start a whiteboard interview not being sure of how things are going to work out. That is a recipe for disaster. Keep in mind: A lot of interviews ask questions that you won’t be able to fully answer on time. So think: What can I show in order to show that I can do this and I am better than other coders. Break things up in Functions (if you can’t remember a method, just make up a function and you will at least have it there. Write something, and start with the easy part.
11. Think about error checks and how you can break this code. Never make assumptions about the input. Assume people are trying to break your code and that Darth Vader is using your function. How will you safeguard it? Always check for false inputs that you don’t want. Here is a trick: Comment in the code, the checks that you want to do... write the function, then tell the interviewer that you would write tests now to make your function fail (but you won't need to actually write the tests).
12. Don’t use bad/confusing names like i and j. Write code that reads well.
13. Test your code: Check for no params, 0, undefined, null, massive arrays, async code, etc... Ask the interviewer if we can make assumption about the code. Can you make the answer return an error? Poke holes into your solution. Are you repeating yourself?
14. Finally talk to the interviewer where you would improve the code. Does it work? Are there different approaches? Is it readable? What would you google to improve? How can performance be improved? Possibly: Ask the interviewer what was the most interesting solution you have seen to this problem
15. If your interviewer is happy with the solution, the interview usually ends here. It is also common that the interviewer asks you extension questions, such as how you would handle the problem if the whole input is too large to fit into memory, or if the input arrives as a stream. This is a common follow-up question at Google, where they care a lot about scale. The answer is usually a divide-and-conquer approach — perform distributed processing of the data and only read certain chunks of the input from disk into memory, write the output back to disk and combine them later.

-= Good code checklist: =-
[ ] It works
[ ] Good use of data structures
[ ] Code Re-use/ Do Not Repeat Yourself
[ ] Modular - makes code more readable, maintainable and testable
[ ] Less than O(N^2). We want to avoid nested loops if we can since they are expensive. Two separate loops are better than 2 nested loops
[ ] Low Space Complexity --> Recursion can cause stack overflow, copying of large arrays may exceed memory of machine

-= Heurestics to ace the question: =-
[ ] Hash Maps are usually the answer to improve Time Complexity
[ ] If it's a sorted array, use Binary tree to achieve O(log N). Divide and Conquer - Divide a data set into smaller chunks and then repeating a process with a subset of data. Binary search is a great example of this
[ ] Try Sorting your input
[ ] Hash tables and precomputed information (i.e. sorted) are some of the best ways to optimize your code
[ ] Look at the Time vs Space tradeoff. Sometimes storing extra state in memory can help the time. (Runtime)
[ ] If the interviewer is giving you advice/tips/hints. Follow them
[ ] Space time tradeoffs: Hastables usually solve this a lot of the times. You use more space, but you can get a time optimization to the process. In programming, you often times can use up a little bit more space to get faster time


Arrays
- pros
-- fast lookup
-- fast push/pop
-- ordered
- cons
-- slow inserts
-- slow deletes
-- fixed size if using static arrays

Hash tables
- collisions
-- lookup goes from O(1) to O(n)
-- take up same memory space
-- use linked list

ES6
hash object
- only strings as keys
Map
- const a = new Map()
- lets you save functions as keys or whatever
- maintains insertion order
Set
- const b = new Set()
- only store keys

Hash
- pros
-- fast lookups
-- fast inserts
-- flexible lookup keys
- cons
-- unordered
-- slow key iteration cuz it has to look up the whole table

LinkedList
- pros
-- fast insertion
-- fast deletion
-- ordered
-- flexible size
- cons
-- slow lookup
-- more memory

Arrays
- cache locality
-- accessing their items in memory faster because they are next to each other

Static Array
- once you reach the limit of that array, it needs to double up in memory to expand


How does JS work
Explain the diff between async vs sync
Js is a single threaded language that can be non-blocking

what is a program
- revisit this video

Stacks & Queues
- pros
-- fast peek
-- fast operations
-- ordered
- cons
-- slow lookup


Trees

Balanced
- O(log n)

Unbalanced
- O(n)
- it is similar to linked list

Binary Search Tree
- pros
-- ordered
-- flexible size
-- better than O(n)
- cons
-- no O(1)


Red Black tree
- auto balance itself
- https://www.cs.usfca.edu/~galles/visualization/RedBlack.html

AVL tree
- auto balance itself
- https://visualgo.net/en/bst

Binary Heap
- max heap
-- root is the biggest number
- min heap
-- root is the smallest number
- balance
- no rules for left and right
- left and right can be any number as long as it is less than root

Priority queue
- left to right insertion
- move bigger number / higher priority up
- similar to airline with captain as priority over passenger eventhough the passenger came first

Binary Heap
- pros
-- better than O(n)
-- priority
-- flexible size
-- fast insert
- cons
-- slow lookup
- insert and delete is O(log n)

Trie
- contains empty root
- letters in nodes with child that forms words
- good for word search like google search
- if u know the length of the word, fast search
- looking car with 3 letters
-- find c, then go down child with depth of 3


Graphs
- cyclic
-- connected
-- nodes form a closed connection
- acyclic
-- not connected
- weighted
-- edges have numbers on it
-- google maps to find shortest path
- undirected
-- nodes can go both ways
- directed
-- nodes go in one direction

Edge List
- shows the edges that connects the nodes
Adjacent list
Adjacent matrix

Graphs
- pros
-- relationship
- cons
-- scaling is hard